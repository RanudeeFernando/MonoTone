# MonoTone ğŸ§ ğŸ’¬

MonoTone is a sleek and intelligent sentiment analysis application designed to interpret the emotional tone of short, conversational content. Whether you're analyzing chat messages, social media posts, user feedback, or even speech from video clips, MonoTone helps you instantly identify the underlying sentiment in both text and voice.

## ğŸ” Sentiment Labels

MonoTone classifies input into one of four custom sentiment categories:

- **Positive** â€” Expresses joy, excitement, appreciation, or other upbeat emotions  
- **Negative** â€” Conveys sadness, frustration, anger, or dissatisfaction  
- **Neutral** â€” Factual or emotionally flat messages  
- **Mixed** â€” Contains both positive and negative emotions or ambiguous tones  

These labels reflect the emotional complexity found in natural, informal communication.

## ğŸ¥ Video-to-Sentiment Workflow

MonoTone supports **sentiment analysis directly from video clips** using the following process:

### How It Works

1. ğŸ“¹ **Video Input**  
   Upload or reference a short video clip (e.g., `.mp4`, `.mov`).

2. ğŸ”Š **Audio Extraction**  
   The system automatically extracts the audio track from the video using tools like `ffmpeg`.

3. ğŸ§¾ **Speech Transcription (Whisper)**  
   The audio is transcribed into text using OpenAIâ€™s **Whisper** model, which excels at handling real-world, informal speech.

4. ğŸ§  **Sentiment Classification**  
   The resulting transcript is passed into MonoToneâ€™s sentiment classifier, outputting one of: **Positive**, **Negative**, **Neutral**, or **Mixed**.

> This makes MonoTone a powerful tool for analyzing emotion in interviews, YouTube clips, vlogs, or any video content with speech.

## âœ¨ Features

- ğŸ¥ Sentiment analysis from video speech
- ğŸ”Š Audio-to-text support via Whisper
- ğŸ§  Fine-tuned transformer-based NLP sentiment model
- ğŸ¯ Four-label sentiment output: Positive, Negative, Neutral, and Mixed
- ğŸ“ Optimized for short, casual, or emotional content
- ğŸ§ª Trained on a custom dataset of 2000+ labeled entries
- ğŸ”„ Easily extendable and customizable
- ğŸ’» Modular design for smooth integration into other tools

## ğŸ› ï¸ Tech Stack

- Python  
- Hugging Face Transformers  
- PyTorch  
- OpenAI Whisper  
- FFmpeg (for audio extraction)  
- Google Colab (for training)  
- Scikit-learn, Pandas, NumPy  

## ğŸ“¦ Dataset

MonoTone is trained on a custom dataset of 2000 short conversational sentences, labeled as **Positive**, **Negative**, **Neutral**, or **Mixed**. Labels were automatically assigned using a combination of rules and pre-trained model insights, designed to match the tone of real-world conversations.


